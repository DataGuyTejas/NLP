{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "df = pd.read_csv('SMSSpamCollection.txt', sep='\\t', names=['message', 'label'])\n",
    "\n",
    "# converting the message and label to a list of tuples\n",
    "data_spam = []\n",
    "for index, row in df.iterrows():\n",
    "    data_spam.append((row['message'], row['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ham',\n",
       "  'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'),\n",
       " ('ham', 'Ok lar... Joking wif u oni...'),\n",
       " ('spam',\n",
       "  \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_spam[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for test preprocessing\n",
    "# Converting to lower case, tokenizing, removing stopwords, lemmentization/stemming\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmentizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(document, stem=True):\n",
    "\n",
    "    words = word_tokenize(document.lower())\n",
    "    words = [w for w in words if w not in stopwords.words('english')]\n",
    "    if stem == True:\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "    else:\n",
    "        words = [lemmentizer.lemmatize(word, pos='v') for word in words]\n",
    "\n",
    "    doc_preprocess = ' '.join(words)\n",
    "\n",
    "    return doc_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['jurong',\n",
       "  'point',\n",
       "  'crazi',\n",
       "  'avail',\n",
       "  'bugi',\n",
       "  'great',\n",
       "  'world',\n",
       "  'buffet',\n",
       "  '...',\n",
       "  'cine',\n",
       "  'got',\n",
       "  'amor',\n",
       "  'wat',\n",
       "  '...'],\n",
       " 'ham')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing all messages\n",
    "\n",
    "data_processed = []\n",
    "\n",
    "for label, message in data_spam:\n",
    "    words = [i for i in preprocess(message, stem=True).split() if len(i) >= 3]\n",
    "    data_processed.append((words, label))\n",
    "\n",
    "data_processed[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to create a word list and then to created a frequency distribution of all words\n",
    "\n",
    "# Get all words\n",
    "def all_words(data):\n",
    "    words = []\n",
    "    for message, label in data:\n",
    "        words.extend(message)\n",
    "    return words\n",
    "\n",
    "# Get Features from Freq Dist\n",
    "def get_features(words):\n",
    "    word_list = FreqDist(words)\n",
    "    word_features = word_list.keys()\n",
    "\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7626\n"
     ]
    }
   ],
   "source": [
    "all_features = get_features(all_words(data_processed))\n",
    "print(len(features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    doc_words = set(document)\n",
    "    features = {}\n",
    "    for feature in all_features:\n",
    "        features[feature] = (feature in doc_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_processed[:int(len(data_processed)*0.8)], data_processed[int(len(data_processed)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = classify.apply_features(extract_features, train)\n",
    "test_set = classify.apply_features(extract_features, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "clf = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set = 0.9921471842046219\n",
      "Accuracy on test set = 0.979372197309417\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on train set = {}\".format(classify.accuracy(clf, train_set)))\n",
    "print(\"Accuracy on test set = {}\".format(classify.accuracy(clf, test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   nokia = True             spam : ham    =    198.2 : 1.0\n",
      "                   award = True             spam : ham    =    194.0 : 1.0\n",
      "                 voucher = True             spam : ham    =    134.3 : 1.0\n",
      "                    code = True             spam : ham    =    108.7 : 1.0\n",
      "                  camera = True             spam : ham    =    100.2 : 1.0\n",
      "                   await = True             spam : ham    =     91.7 : 1.0\n",
      "                  latest = True             spam : ham    =     83.1 : 1.0\n",
      "                  servic = True             spam : ham    =     80.3 : 1.0\n",
      "                 attempt = True             spam : ham    =     74.6 : 1.0\n",
      "                  urgent = True             spam : ham    =     71.8 : 1.0\n",
      "                 landlin = True             spam : ham    =     70.3 : 1.0\n",
      "                  privat = True             spam : ham    =     70.3 : 1.0\n",
      "                     txt = True             spam : ham    =     68.8 : 1.0\n",
      "                    land = True             spam : ham    =     66.1 : 1.0\n",
      "                deliveri = True             spam : ham    =     61.8 : 1.0\n",
      "                   appli = True             spam : ham    =     60.1 : 1.0\n",
      "                     100 = True             spam : ham    =     57.6 : 1.0\n",
      "                    draw = True             spam : ham    =     57.6 : 1.0\n",
      "                   video = True             spam : ham    =     55.0 : 1.0\n",
      "                   mobil = True             spam : ham    =     53.7 : 1.0\n",
      "                  reveal = True             spam : ham    =     49.0 : 1.0\n",
      "                  select = True             spam : ham    =     46.6 : 1.0\n",
      "                    club = True             spam : ham    =     44.8 : 1.0\n",
      "                    oper = True             spam : ham    =     44.8 : 1.0\n",
      "                     opt = True             spam : ham    =     44.8 : 1.0\n",
      "                   orang = True             spam : ham    =     42.9 : 1.0\n",
      "                    rate = True             spam : ham    =     41.1 : 1.0\n",
      "                motorola = True             spam : ham    =     40.5 : 1.0\n",
      "                 collect = True             spam : ham    =     39.8 : 1.0\n",
      "                   pound = True             spam : ham    =     39.3 : 1.0\n",
      "               statement = True             spam : ham    =     37.1 : 1.0\n",
      "                    1000 = True             spam : ham    =     36.2 : 1.0\n",
      "                  txting = True             spam : ham    =     36.2 : 1.0\n",
      "               congratul = True             spam : ham    =     34.5 : 1.0\n",
      "                     del = True             spam : ham    =     32.0 : 1.0\n",
      "                  flight = True             spam : ham    =     32.0 : 1.0\n",
      "                 sunshin = True             spam : ham    =     32.0 : 1.0\n",
      "                    user = True             spam : ham    =     32.0 : 1.0\n",
      "                  colour = True             spam : ham    =     30.1 : 1.0\n",
      "                    cash = True             spam : ham    =     28.6 : 1.0\n",
      "                 contact = True             spam : ham    =     28.1 : 1.0\n",
      "                    comp = True             spam : ham    =     27.7 : 1.0\n",
      "                  member = True             spam : ham    =     27.7 : 1.0\n",
      "                     per = True             spam : ham    =     27.5 : 1.0\n",
      "                    info = True             spam : ham    =     26.9 : 1.0\n",
      "                     sex = True             spam : ham    =     26.9 : 1.0\n",
      "                  custom = True             spam : ham    =     26.7 : 1.0\n",
      "                   music = True             spam : ham    =     26.5 : 1.0\n",
      "                     box = True             spam : ham    =     26.2 : 1.0\n",
      "                  receiv = True             spam : ham    =     25.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Getting feature importances\n",
    "print(clf.show_most_informative_features(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier stored at  nb_spam_classifier.pickle\n"
     ]
    }
   ],
   "source": [
    "## storing the classifier on disk for later usage\n",
    "import pickle\n",
    "f = open('nb_spam_classifier.pickle', 'wb')\n",
    "pickle.dump(clf,f)\n",
    "print('Classifier stored at ', f.name)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
